---
name: bert_base_squad_uncased-4.23.0
gops: 71.01
shapes:
  - [[1, 384], [1, 384], [1, 384]]

model: $(home)/bert_base_squad_uncased-4.23.0.onnx
time: true
precision: true

excepts: "/bert/Mul_output_0_Mul,\
      /bert/encoder/layer.0/attention/self/Add_output_0_Add,\
      /bert/encoder/layer.1/attention/self/Add_output_0_Add,\
      /bert/encoder/layer.2/attention/self/Add_output_0_Add,\
      /bert/encoder/layer.3/attention/self/Add_output_0_Add,\
      /bert/encoder/layer.4/attention/self/Add_output_0_Add,\
      /bert/encoder/layer.5/attention/self/Add_output_0_Add,\
      /bert/encoder/layer.6/attention/self/Add_output_0_Add,\
      /bert/encoder/layer.7/attention/self/Add_output_0_Add,\
      /bert/encoder/layer.8/attention/self/Add_output_0_Add,\
      /bert/encoder/layer.9/attention/self/Add_output_0_Add,\
      /bert/encoder/layer.10/attention/self/Add_output_0_Add,\
      /bert/encoder/layer.11/attention/self/Add_output_0_Add"

mlir_transform: model_transform.py
  --model_name $(name)
  --model_def $(home)/$(name).onnx
  --test_input $(root)/dataset/npz_input/squad_uncased_data.npz
  --input_shapes [$(shape_param)]
  --test_result $(workdir)/$(name)_top_outputs.npz
  --excepts $(excepts)
  --mlir $(workdir)/$(name).mlir

mlir_calibration: run_calibration.py $(workdir)/$(name).mlir
  --dataset $(root)/dataset/SQuAD/mlir
  --input_num 10
  -o $(workdir)/$(name)_cali_table

BM1684X:
  deploy:
    - model_deploy.py  --mlir $(workdir)/$(name).mlir
      --quantize F32
      --chip $(target)
      --tolerance 0.99,0.99
      --test_input $(workdir)/$(name)_in_f32.npz
      --test_reference $(workdir)/$(name)_top_outputs.npz
      --model $(workdir)/$(name)_$(target)_f32.bmodel

    - model_deploy.py  --mlir $(workdir)/$(name).mlir
      --quantize F16
      --chip $(target)
      --tolerance 0.95,0.85
      --test_input $(workdir)/$(name)_in_f32.npz
      --test_reference $(workdir)/$(name)_top_outputs.npz
      --model $(workdir)/$(name)_$(target)_f16.bmodel

    - model_deploy.py  --mlir $(workdir)/$(name).mlir
      --quantize BF16
      --chip $(target)
      --tolerance 0.95,0.85
      --test_input $(workdir)/$(name)_in_f32.npz
      --test_reference $(workdir)/$(name)_top_outputs.npz
      --model $(workdir)/$(name)_$(target)_Bf16.bmodel

    - model_deploy.py  --mlir $(workdir)/$(name).mlir
      --quantize INT8
      --chip $(target)
      --tolerance 0.85,0.40
      --calibration_table $(workdir)/$(name)_cali_table
      --quantize_table $(home)/$(name)_qtable
      --test_input $(workdir)/$(name)_in_f32.npz
      --test_reference $(workdir)/$(name)_top_outputs.npz
      --model $(workdir)/$(name)_$(target)_int8_sym.bmodel

  harness:
    type: bert
    args:
      - name: FP32
        bmodel: $(workdir)/$(name)_$(target)_f32.bmodel
        model_type: "onnx"
      - name: FP16
        bmodel: $(workdir)/$(name)_$(target)_f16.bmodel
        model_type: "onnx"
      - name: BF16
        bmodel: $(workdir)/$(name)_$(target)_BF16.bmodel
        model_type: "onnx"
      - name: INT8-sym
        bmodel: $(workdir)/$(name)_$(target)_int8_sym.bmodel
        model_type: "onnx"


val_file: $(root)/dataset/SQuAD/val/dev-v1.1.json
val_count: 10833
